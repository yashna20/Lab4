{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-Idf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: Front, TF-IDF: 0.0159\n",
      "\tWord: alliance, TF-IDF: 0.0159\n",
      "\tWord: After, TF-IDF: 0.00795\n",
      "Top words in document 2\n",
      "\tWord: The, TF-IDF: 0.03899\n",
      "\tWord: chief, TF-IDF: 0.01559\n",
      "\tWord: her, TF-IDF: 0.01559\n",
      "Top words in document 3\n",
      "\tWord: which, TF-IDF: 0.00922\n",
      "\tWord: “, TF-IDF: 0.00922\n",
      "\tWord: ”, TF-IDF: 0.00922\n"
     ]
    }
   ],
   "source": [
    "document1 = tb(\"\"\"After a decade of losing power, the Left Front, in alliance with the Congress and the newly formed Indian\n",
    "Secular Front (ISF), on Sunday projected itself as a \"third alternative force\" in the emerging Trinamool Congress versus \n",
    "BJP political binary in West Bengal, but chinks were evident in the nascent alliance.\"\"\")\n",
    "\n",
    "document2 = tb(\"\"\"West Bengal chief minister and Trinamool Congress (TMC) chief Mamata Banerjee has been authorised by her \n",
    "party to take the final call on selecting the candidates for the upcoming Assembly polls. The decision was taken at a \n",
    "meeting of 12-member election committee of the TMC at her residence in Kalighat on Monday.\"\"\")\n",
    "\n",
    "document3 = tb(\"\"\"Well aware of the challenge at hand, the TMC, which has now been in power for nearly 10 years and faces \n",
    "anti-incumbency, has sought to turn the election narrative into an “insider vs outsider” contest — pushing the idea that \n",
    "the BJP has brought in “people from outside” who do not understand Bengal and its culture. Besides, the party, which has \n",
    "roped in political strategist Prashant Kishor to fine tune its campaign, has been stressing on development works done by \n",
    "the Mamata Banerjee government.\"\"\")\n",
    "\n",
    "bloblist = [document1, document2, document3]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jacard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics import*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ['apple', 'grape', 'mango', 'orange']\n",
    "h = ['orange', 'pineapple', 'banana', 'kiwi']\n",
    "set_g=set(g)\n",
    "set_h=set(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1428571428571429"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=1-jaccard_distance(set_g,set_h)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "1 0 0 0 0 0 \n",
      "2 0 0 0 0 0 \n",
      "3 0 0 0 0 0 \n",
      "4 0 0 0 0 0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    printDistances(distances, len(token1), len(token2))\n",
    "    return 0\n",
    "\n",
    "def printDistances(distances, token1Length, token2Length):\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()\n",
    "        \n",
    "levenshteinDistanceDP(\"kelm\", \"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = \"I went for vacation with my family to Thailand\"\n",
    "\n",
    "doc_2 = \"My favourite destination for vacation is Switzerland\"\n",
    "\n",
    "\n",
    "documents = [doc_1, doc_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>family</th>\n",
       "      <th>favourite</th>\n",
       "      <th>for</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "      <th>switzerland</th>\n",
       "      <th>thailand</th>\n",
       "      <th>to</th>\n",
       "      <th>vacation</th>\n",
       "      <th>went</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       destination  family  favourite  for  is  my  switzerland  thailand  to  \\\n",
       "doc_1            0       1          0    1   0   1            0         1   1   \n",
       "doc_2            1       0          1    1   1   1            1         0   0   \n",
       "\n",
       "       vacation  went  with  \n",
       "doc_1         1     1     1  \n",
       "doc_2         1     0     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['doc_1', 'doc_2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40089186]\n",
      " [0.40089186 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFID vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?', ]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max and Min df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import pickle \n",
    "#import mglearn\n",
    "import time\n",
    "\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # doesn't split at apostrophes\n",
    "import nltk\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [\"He is ::having a great Time, at the park time?\",\n",
    "       \"She, unlike most women, is a big player on the park's grass.\",\n",
    "       \"she can't be going\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['park']\n",
      "\n",
      "Only 'park' becomes the vocabulary of the document term matrix (dtm) because it appears in 2 out of 3 documents, meaning 0.66% of the time.      \n",
      "The rest of the words such as 'big' appear only in 1 out of 3 documents, meaning 0.33%. which is why they don't appear\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(stop_words=\"english\", analyzer='word',ngram_range=(1, 1), max_df=1.0, min_df=0.6, max_features=None)\n",
    "\n",
    "count_train = count_vec.fit(txt)\n",
    "bag_of_words = count_vec.transform(txt)\n",
    "\n",
    "print(count_vec.get_feature_names())\n",
    "print(\"\\nOnly 'park' becomes the vocabulary of the document term matrix (dtm) because it appears in 2 out of 3 documents, \\\n",
    "meaning 0.66% of the time.\\\n",
    "      \\nThe rest of the words such as 'big' appear only in 1 out of 3 documents, meaning 0.33%. which is why they don't appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'going', 'grass', 'great', 'having', 'player', 'time', 'unlike', 'women']\n",
      "\n",
      "Only 'park' is ignored because it appears in 2 out of 3 documents, meaning 0.66% of the time.\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(stop_words=\"english\", analyzer='word',ngram_range=(1, 1), max_df=0.50, min_df=1, max_features=None)\n",
    "\n",
    "count_train = count_vec.fit(txt)\n",
    "bag_of_words = count_vec.transform(txt)\n",
    "\n",
    "print(count_vec.get_feature_names())\n",
    "print(\"\\nOnly 'park' is ignored because it appears in 2 out of 3 documents, meaning 0.66% of the time.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
